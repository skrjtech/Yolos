{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340ec941-fc08-4ef9-80f6-6245f7cc9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5038e9cc-18b2-496e-a10a-a7c16e3b5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(bbox1: torch.Tensor, bbox2: torch.Tensor):\n",
    "    \"\"\"\n",
    "    bbox1: Shape(N, 4)\n",
    "    bbox2: Shape(M, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    N = bbox1.size(0)\n",
    "    M = bbox2.size(0)\n",
    "    \n",
    "    lt = torch.max(\n",
    "        bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "    )\n",
    "    \n",
    "    rb = torch.min(\n",
    "        bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "        bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "    )\n",
    "    \n",
    "    wh = torch.clamp(rb - lt, min=0) # [wh < 0] = 0 # clip at 0\n",
    "    inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "    # Compute area of the bboxes\n",
    "    area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "    area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "    area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "    area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "    union = area1 + area2 - inter # [N, M, 2]\n",
    "    iou = inter / union           # [N, M, 2]\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "08365dd4-47e7-4459-aa11-195588384d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Norm2DNorm(Boxes: torch.Tensor, S: int):\n",
    "    Target = torch.zeros_like(Boxes)\n",
    "    Target[..., :2] = Boxes[..., :2] / torch.Tensor([S]).to(torch.float) - .5 * Boxes[..., 2:]\n",
    "    Target[..., 2:] = Boxes[..., :2] / torch.Tensor([S]).to(torch.float) + .5 * Boxes[..., 2:]\n",
    "    return Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "2c6dcadf-3e72-4756-ba1e-5d000da69d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yololoss(S: int, B: int, C: int, LambdaObj: float=5., LambdaNoObj: float=.5):\n",
    "    N = B * 5 + C\n",
    "    CI = [4, 9]\n",
    "    BI = [0, 1, 2, 3, 5, 6, 7, 8]\n",
    "    LI = [B * 5 + idx for idx in range(C)]\n",
    "    XYI = [0, 1]\n",
    "    WHI = [2, 3]\n",
    "    def __CALL__(Prediction: torch.Tensor, Target: torch.Tensor):\n",
    "        BatchSize = Prediction.size(0)\n",
    "        coordMask = (Target[..., 4] == 1).unsqueeze(-1).expand_as(Target)\n",
    "        noobjMask = (Target[..., 4] == 0).unsqueeze(-1).expand_as(Target)\n",
    "\n",
    "        coordP = Prediction[coordMask].reshape(-1, N)  # [coord_n, N]\n",
    "        noobjP = Prediction[noobjMask].reshape(-1, N)  # [coord_n, N]\n",
    "\n",
    "        coordT = Target[coordMask].reshape(-1, N)  # [coord_n, N]\n",
    "        noobjT = Target[noobjMask].reshape(-1, N)  # [coord_n, N]\n",
    "\n",
    "        # Class Label\n",
    "        ClassP = coordP[..., LI].reshape(-1, C)  # [coord_n, C]\n",
    "        ClassT = coordT[..., LI].reshape(-1, C)  # [coord_n, C]\n",
    "        # No Object Confidence\n",
    "        NoObjP = noobjP[..., CI].reshape(-1, 1)  # [nooobj_n, 1]\n",
    "        NoObjT = noobjT[..., CI].reshape(-1, 1)  # [nooobj_n, 1]\n",
    "        # Object Confidence\n",
    "        ConfP = coordP[..., CI].reshape(-1, 1);  # [coord_n, 1]\n",
    "        # BBox\n",
    "        BBoxP = coordP[..., BI].reshape(-1, B, 4)  # [coord_n, B, 4(XYWH)]\n",
    "        BBoxT = coordT[..., BI].reshape(-1, B, 4)  # [coord_n, B, 4(XYWH)]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            BBoxP = Norm2DNorm(BBoxP.reshape(-1, 4), S)\n",
    "            BBoxT = Norm2DNorm(BBoxT.reshape(-1, 4), S)\n",
    "            iou, iouIndex = torch.max(IoU(BBoxP.reshape(-1, 4), BBoxT.reshape(-1, 4)), dim=0)\n",
    "\n",
    "        NSize= BBoxP.size(0)\n",
    "        BBoxP = BBoxP.unsqueeze(0).expand(NSize, NSize, 4)[list(range(NSize)), iouIndex]\n",
    "        BBoxT = BBoxT.unsqueeze(0).expand(NSize, NSize, 4)[list(range(NSize)), iouIndex]\n",
    "        ConfP = ConfP.unsqueeze(0).expand(NSize, NSize, 1)[list(range(NSize)), iouIndex]\n",
    "        \n",
    "        lossXY = torch.nn.functional.mse_loss(BBoxP[..., XYI], BBoxT[..., XYI], reduction=\"sum\")\n",
    "        lossWH = torch.nn.functional.mse_loss(torch.sqrt(BBoxP[..., WHI]), torch.sqrt(BBoxT[..., WHI]), reduction=\"sum\")\n",
    "\n",
    "        lossObj = torch.nn.functional.mse_loss(ConfP.reshape(-1), iou, reduction=\"sum\")\n",
    "        lossNObj = torch.nn.functional.mse_loss(NoObjP, NoObjT, reduction=\"sum\")\n",
    "        lossClass = torch.nn.functional.mse_loss(ClassP, ClassT, reduction=\"sum\")\n",
    "        loss = (LambdaObj * (lossXY + lossWH) + LambdaNoObj * (lossNObj) + (lossObj + lossClass)) / BatchSize\n",
    "        return loss\n",
    "    return __CALL__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d02e3975-1485-4482-b7e5-5ebdf5e41832",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBox1 = torch.zeros(1, 7, 7, 13)\n",
    "BBox2 = torch.zeros(1, 7, 7, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6c9cbc56-8b80-4645-8b5d-f9d1ffc06e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BBox1[0, 1, 1] = torch.Tensor([0.11, 0.11, 0.4, 0.4, .9, 0.9, 0.9, 0.4, 0.4, .9, 0., 1., 0.])\n",
    "BBox2[0, 1, 1] = torch.Tensor([0.1, 0.1, 0.4, 0.4, 1., 0.1, 0.1, 0.4, 0.4, 1., 0., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "75de3f5b-53c7-4dde-9797-ba2857ff5450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0148)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yololoss(7, 2, 3)(BBox1, BBox2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4a6bab44-c567-427a-b279-94399c00c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boxes1 = torch.Tensor([\n",
    "    [100, 100, 250, 250],\n",
    "    [10, 10, 50, 50],\n",
    "    [50, 75, 70, 80],\n",
    "    [250, 250, 300, 300],\n",
    "])\n",
    "Target = torch.Tensor([\n",
    "    [90, 90, 300, 300],\n",
    "    [20, 20, 74, 75],\n",
    "    [251, 251, 300, 300],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "0258be28-18a0-4b5b-b375-644bb3ae0d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.Tensor([0.1, 0.4, 0.2, 0.9])\n",
    "iou = IoU(Target, Boxes1)\n",
    "iou, index = iou.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "90e0a04e-6724-4a06-a783-48dee7f52fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = torch.zeros(10)\n",
    "TF = torch.ones(10)\n",
    "\n",
    "scores, index = torch.sort(scores, descending=True)\n",
    "TP[torch.where(iou[index] > 0.5)] = 1.\n",
    "TF[torch.where(iou[index] > 0.5)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "361952c6-6088-4065-bf15-83d3dc048602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP(Scores: torch.Tensor, Correct: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "    if torch.sum(Correct) == 0:\n",
    "        # return torch.sum(Correct), Correct, Correct\n",
    "        return 0.\n",
    "\n",
    "    IndexSort = torch.sort(Scores, descending=True)[-1] # 降順\n",
    "    # Scores = Scores[IndexSort]\n",
    "    Correct = Correct[IndexSort]\n",
    "\n",
    "    TP = torch.cumsum(Correct, dim=-1)\n",
    "    Precision = TP / (torch.arange(TP.size(0)) + 1.)\n",
    "    Recall = TP / torch.sum(Correct, dim=-1)\n",
    "    \n",
    "    # PrecisionFlip = Precision.flip(dims=(0,))\n",
    "    # PrecisionFlip = torch.cummax(PrecisionFlip, dim=0)[0].flip(dims=(0,))\n",
    "\n",
    "    Precision = torch.concat([torch.Tensor([0]), Precision, torch.Tensor([0])], dim=-1)\n",
    "    Recall = torch.concat([torch.Tensor([0]), Recall, torch.Tensor([1])], dim=-1)\n",
    "\n",
    "    Recall = Recall[1:] - Recall[:-1]\n",
    "    \n",
    "    return torch.sum(Recall * Precision[1:], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "9ba29a94-f3fa-4dc8-9758-4c65edcd17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = torch.Tensor([95, 92, 85, 80, 70, 60])\n",
    "Correct = torch.Tensor([1, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "17a055b7-1f96-4e2f-9ccd-917922f1e6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8542)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AP(Scores, Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26b5ee-1492-42ea-91a8-40252013057c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb74826-e454-4a5a-9550-c968889e2047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d1120-1a66-486c-b813-314afed9197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoUCul(P, T):\n",
    "        \"\"\"\n",
    "        P (input): [Batch, coord_n, xywh]\n",
    "        T (input): [Batch, coord_n, xywh]\n",
    "        \"\"\"\n",
    "\n",
    "        XYI = [0, 1]\n",
    "        WHI = [2, 3]\n",
    "\n",
    "        S = 7\n",
    "        P = P.clone()\n",
    "        T = T.clone()\n",
    "\n",
    "        PXYMIN = P[..., XYI] / float(S) - 0.5 * P[..., WHI]\n",
    "        PXYMAX = P[..., XYI] / float(S) + 0.5 * P[..., WHI]\n",
    "\n",
    "        TXYMIN = T[..., XYI] / float(S) - 0.5 * T[..., WHI]\n",
    "        TXYMAX = T[..., XYI] / float(S) + 0.5 * T[..., WHI]\n",
    "\n",
    "        lt = torch.max(PXYMIN, TXYMIN)\n",
    "        rb = torch.min(PXYMAX, TXYMAX)\n",
    "\n",
    "        wh = torch.clamp(rb - lt, min=0.)\n",
    "        intersect = (wh[..., 0] * wh[..., 1])\n",
    "\n",
    "        Area1 = (PXYMAX - PXYMIN)\n",
    "        Area1 = Area1[..., 0] * Area1[..., 1]\n",
    "        Area2 = (TXYMAX - TXYMIN)\n",
    "        Area2 = Area2[..., 0] * Area2[..., 1]\n",
    "        Union = Area1 + Area2 - intersect\n",
    "\n",
    "        iou = intersect / Union\n",
    "        return torch.max(iou.reshape(-1, 2), dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
